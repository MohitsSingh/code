{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# drawing imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path variables\n",
    "# set paths here and you're good to go...\n",
    "\n",
    "# directory containing coco-a annotations\n",
    "COCOA_DIR = 'D:/datasets/coco/'\n",
    "# coco-a json file\n",
    "COCOA_ANN = 'cocoa_beta2015.json'\n",
    "# directory containing VisualVerbnet\n",
    "VVN_DIR = COCOA_DIR\n",
    "# vvn json file\n",
    "VVN_ANN = 'visual_verbnet_beta2015.json'\n",
    "# directory containing the MS COCO images\n",
    "COCO_IMG_DIR = 'D:/datasets/coco/images'\n",
    "# directory containing the MS COCO Python API\n",
    "COCO_API_DIR = 'D:/datasets/coco/PythonAPI'\n",
    "# directory containing the MS COCO annotations\n",
    "COCO_ANN_DIR = 'D:/datasets/coco/annotations'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading COCO-a annotations...\n",
      "Done, (t=1.16s).\n"
     ]
    }
   ],
   "source": [
    "# load cocoa annotations\n",
    "\n",
    "print(\"Loading COCO-a annotations...\")\n",
    "tic = time.time()\n",
    "\n",
    "with open(\"{0}/{1}\".format(COCOA_DIR,COCOA_ANN)) as f:\n",
    "    cocoa = json.load(f)\n",
    "\n",
    "# annotations with agreement of at least 1 mturk annotator\n",
    "cocoa_1 = cocoa['annotations']['1']\n",
    "# annotations with agreement of at least 2 mturk annotator\n",
    "cocoa_2 = cocoa['annotations']['2']\n",
    "# annotations with agreement of at least 3 mturk annotator\n",
    "cocoa_3 = cocoa['annotations']['3']\n",
    "\n",
    "print(\"Done, (t={0:.2f}s).\".format(time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29628"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cocoa_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VisualVerbNet...\n",
      "Done, (t=0.05s).\n"
     ]
    }
   ],
   "source": [
    "# load visual verbnet\n",
    "\n",
    "print(\"Loading VisualVerbNet...\")\n",
    "tic = time.time()\n",
    "\n",
    "with open(\"{0}/{1}\".format(VVN_DIR,VVN_ANN)) as f:\n",
    "    vvn = json.load(f)\n",
    "\n",
    "# list of 145 visual actions contained in VVN\n",
    "visual_actions = vvn['visual_actions']\n",
    "# list of 17 visual adverbs contained in VVN\n",
    "visual_adverbs = vvn['visual_adverbs']\n",
    "    \n",
    "print(\"Done, (t={0:.2f}s).\".format(time.time() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Category: [nutrition]\n",
      "\t - id:[46], visual_action:[chew]\n",
      "\t - id:[47], visual_action:[cook]\n",
      "\t - id:[48], visual_action:[devour]\n",
      "\t - id:[49], visual_action:[drink]\n",
      "\t - id:[50], visual_action:[eat]\n",
      "\t - id:[51], visual_action:[prepare]\n",
      "\t - id:[52], visual_action:[spread]\n",
      "Visual Category: [perception]\n",
      "\t - id:[87], visual_action:[listen]\n",
      "\t - id:[88], visual_action:[look]\n",
      "\t - id:[89], visual_action:[sniff]\n",
      "\t - id:[90], visual_action:[taste]\n",
      "\t - id:[91], visual_action:[touch]\n",
      "Visual Category: [objects]\n",
      "\t - id:[53], visual_action:[bend_object]\n",
      "\t - id:[54], visual_action:[break]\n",
      "\t - id:[55], visual_action:[brush]\n",
      "\t - id:[56], visual_action:[build]\n",
      "\t - id:[57], visual_action:[carry]\n",
      "\t - id:[58], visual_action:[catch]\n",
      "\t - id:[59], visual_action:[clear]\n",
      "\t - id:[60], visual_action:[cut]\n",
      "\t - id:[61], visual_action:[disassemble]\n",
      "\t - id:[62], visual_action:[drive]\n",
      "\t - id:[63], visual_action:[drop]\n",
      "\t - id:[64], visual_action:[exchange]\n",
      "\t - id:[65], visual_action:[fill]\n",
      "\t - id:[66], visual_action:[get]\n",
      "\t - id:[67], visual_action:[lay]\n",
      "\t - id:[68], visual_action:[light]\n",
      "\t - id:[69], visual_action:[mix]\n",
      "\t - id:[70], visual_action:[pour]\n",
      "\t - id:[71], visual_action:[put]\n",
      "\t - id:[72], visual_action:[read]\n",
      "\t - id:[73], visual_action:[remove]\n",
      "\t - id:[74], visual_action:[repair]\n",
      "\t - id:[75], visual_action:[ride]\n",
      "\t - id:[76], visual_action:[row]\n",
      "\t - id:[77], visual_action:[sail]\n",
      "\t - id:[78], visual_action:[separate]\n",
      "\t - id:[79], visual_action:[show]\n",
      "\t - id:[80], visual_action:[spill]\n",
      "\t - id:[81], visual_action:[spray]\n",
      "\t - id:[82], visual_action:[steal]\n",
      "\t - id:[83], visual_action:[throw]\n",
      "\t - id:[84], visual_action:[use]\n",
      "\t - id:[85], visual_action:[wash]\n",
      "\t - id:[86], visual_action:[wear]\n",
      "Visual Category: [solo]\n",
      "\t - id:[139], visual_action:[blow]\n",
      "\t - id:[140], visual_action:[clap]\n",
      "\t - id:[141], visual_action:[cry]\n",
      "\t - id:[142], visual_action:[draw]\n",
      "\t - id:[143], visual_action:[groan]\n",
      "\t - id:[144], visual_action:[laugh]\n",
      "\t - id:[145], visual_action:[paint]\n",
      "\t - id:[146], visual_action:[photograph]\n",
      "\t - id:[147], visual_action:[play]\n",
      "\t - id:[148], visual_action:[play_baseball_solo]\n",
      "\t - id:[149], visual_action:[play_basketball_solo]\n",
      "\t - id:[150], visual_action:[play_frisbee_solo]\n",
      "\t - id:[151], visual_action:[play_instrument]\n",
      "\t - id:[152], visual_action:[play_soccer_solo]\n",
      "\t - id:[153], visual_action:[play_tennis_solo]\n",
      "\t - id:[154], visual_action:[pose]\n",
      "\t - id:[155], visual_action:[sing]\n",
      "\t - id:[156], visual_action:[skate]\n",
      "\t - id:[157], visual_action:[ski]\n",
      "\t - id:[158], visual_action:[sleep]\n",
      "\t - id:[159], visual_action:[smile]\n",
      "\t - id:[160], visual_action:[snowboard]\n",
      "\t - id:[161], visual_action:[surf]\n",
      "\t - id:[162], visual_action:[write]\n",
      "Visual Category: [communication]\n",
      "\t - id:[18], visual_action:[call]\n",
      "\t - id:[19], visual_action:[shout]\n",
      "\t - id:[20], visual_action:[signal]\n",
      "\t - id:[21], visual_action:[talk]\n",
      "\t - id:[22], visual_action:[whistle]\n",
      "\t - id:[23], visual_action:[wink]\n",
      "Visual Category: [contact]\n",
      "\t - id:[24], visual_action:[avoid]\n",
      "\t - id:[25], visual_action:[bite]\n",
      "\t - id:[26], visual_action:[bump]\n",
      "\t - id:[27], visual_action:[caress]\n",
      "\t - id:[28], visual_action:[hit]\n",
      "\t - id:[29], visual_action:[hold]\n",
      "\t - id:[30], visual_action:[hug]\n",
      "\t - id:[31], visual_action:[kick]\n",
      "\t - id:[32], visual_action:[kiss]\n",
      "\t - id:[33], visual_action:[lick]\n",
      "\t - id:[34], visual_action:[lift]\n",
      "\t - id:[35], visual_action:[massage]\n",
      "\t - id:[36], visual_action:[pet]\n",
      "\t - id:[37], visual_action:[pinch]\n",
      "\t - id:[38], visual_action:[poke]\n",
      "\t - id:[39], visual_action:[pull]\n",
      "\t - id:[40], visual_action:[punch]\n",
      "\t - id:[41], visual_action:[push]\n",
      "\t - id:[42], visual_action:[reach]\n",
      "\t - id:[43], visual_action:[slap]\n",
      "\t - id:[44], visual_action:[squeeze]\n",
      "\t - id:[45], visual_action:[tickle]\n",
      "Visual Category: [social]\n",
      "\t - id:[115], visual_action:[accompany]\n",
      "\t - id:[116], visual_action:[be_with]\n",
      "\t - id:[117], visual_action:[chase]\n",
      "\t - id:[118], visual_action:[dance]\n",
      "\t - id:[119], visual_action:[dine]\n",
      "\t - id:[120], visual_action:[dress]\n",
      "\t - id:[121], visual_action:[feed]\n",
      "\t - id:[122], visual_action:[fight]\n",
      "\t - id:[123], visual_action:[follow]\n",
      "\t - id:[124], visual_action:[give]\n",
      "\t - id:[125], visual_action:[groom]\n",
      "\t - id:[126], visual_action:[help]\n",
      "\t - id:[127], visual_action:[hunt]\n",
      "\t - id:[128], visual_action:[kill]\n",
      "\t - id:[129], visual_action:[meet]\n",
      "\t - id:[130], visual_action:[pay]\n",
      "\t - id:[131], visual_action:[play_baseball]\n",
      "\t - id:[132], visual_action:[play_basketball]\n",
      "\t - id:[133], visual_action:[play_frisbee]\n",
      "\t - id:[134], visual_action:[play_soccer]\n",
      "\t - id:[135], visual_action:[play_tennis]\n",
      "\t - id:[136], visual_action:[precede]\n",
      "\t - id:[137], visual_action:[shake_hands]\n",
      "\t - id:[138], visual_action:[teach]\n",
      "Visual Category: [posture]\n",
      "\t - id:[92], visual_action:[balance]\n",
      "\t - id:[93], visual_action:[bend]\n",
      "\t - id:[94], visual_action:[bow]\n",
      "\t - id:[95], visual_action:[climb]\n",
      "\t - id:[96], visual_action:[crouch]\n",
      "\t - id:[97], visual_action:[fall]\n",
      "\t - id:[98], visual_action:[float]\n",
      "\t - id:[99], visual_action:[fly]\n",
      "\t - id:[100], visual_action:[hang]\n",
      "\t - id:[101], visual_action:[jump]\n",
      "\t - id:[102], visual_action:[kneel]\n",
      "\t - id:[103], visual_action:[lean]\n",
      "\t - id:[104], visual_action:[lie]\n",
      "\t - id:[105], visual_action:[perch]\n",
      "\t - id:[106], visual_action:[recline]\n",
      "\t - id:[107], visual_action:[roll]\n",
      "\t - id:[108], visual_action:[run]\n",
      "\t - id:[109], visual_action:[sit]\n",
      "\t - id:[110], visual_action:[squat]\n",
      "\t - id:[111], visual_action:[stand]\n",
      "\t - id:[112], visual_action:[straddle]\n",
      "\t - id:[113], visual_action:[swim]\n",
      "\t - id:[114], visual_action:[walk]\n"
     ]
    }
   ],
   "source": [
    "# visual actions in VVN by category\n",
    "\n",
    "# each visual action is a dictionary with the following properties:\n",
    "#  - id:            unique id within VVN\n",
    "#  - name:          name of the visual action\n",
    "#  - category:      visual category as defined in the paper\n",
    "#  - definition:    [empty]\n",
    "#                   an english language description of the visual action\n",
    "#  - verbnet_class: [empty]\n",
    "#                   corresponding verbnet (http://verbs.colorado.edu/verb-index/index.php) entry id for each visual action\n",
    "\n",
    "for cat in set([x['category'] for x in visual_actions]):\n",
    "    print(\"Visual Category: [{0}]\".format(cat))\n",
    "    for va in [x for x in visual_actions if x['category']==cat]:\n",
    "        print(\"\\t - id:[{0}], visual_action:[{1}]\".format(va['id'],va['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Category: [emotion]\n",
      "\t - id:[1], visual_adverb:[anger]\n",
      "\t - id:[2], visual_adverb:[disgust]\n",
      "\t - id:[3], visual_adverb:[fear]\n",
      "\t - id:[4], visual_adverb:[happiness]\n",
      "\t - id:[5], visual_adverb:[neutral]\n",
      "\t - id:[6], visual_adverb:[sadness]\n",
      "\t - id:[7], visual_adverb:[surprise]\n",
      "Visual Category: [distance]\n",
      "\t - id:[14], visual_adverb:[far]\n",
      "\t - id:[15], visual_adverb:[full_contact]\n",
      "\t - id:[16], visual_adverb:[light_contact]\n",
      "\t - id:[17], visual_adverb:[near]\n",
      "Visual Category: [location]\n",
      "\t - id:[8], visual_adverb:[above]\n",
      "\t - id:[9], visual_adverb:[behind]\n",
      "\t - id:[10], visual_adverb:[below]\n",
      "\t - id:[11], visual_adverb:[in_front]\n",
      "\t - id:[12], visual_adverb:[left]\n",
      "\t - id:[13], visual_adverb:[right]\n"
     ]
    }
   ],
   "source": [
    "# visual adverbs in VVN by category\n",
    "\n",
    "# each visual adverb is a dictionary with the following properties:\n",
    "#  - id:            unique id within VVN\n",
    "#  - name:          name of the visual action\n",
    "#  - category:      visual category as defined in the paper\n",
    "#  - definition:    [empty]\n",
    "#                   an english language description of the visual action\n",
    "\n",
    "# NOTE: relative_location is the location of the object with respect to the subject.\n",
    "# It is not with respect to the reference frame of the image.\n",
    "# i.e. if you where the subject, where is the object with respect to you?\n",
    "\n",
    "for cat in set([x['category'] for x in visual_adverbs]):\n",
    "    print(\"Visual Category: [{0}]\".format(cat))\n",
    "    for va in [x for x in visual_adverbs if x['category']==cat]:\n",
    "        print(\"\\t - id:[{0}], visual_adverb:[{1}]\".format(va['id'],va['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_to_action = {}\n",
    "for p in visual_actions:\n",
    "    u = dict(p)\n",
    "    id_to_action[u['id']] = u\n",
    "    \n",
    "id_to_adverb = {}\n",
    "for p in visual_adverbs:\n",
    "    u = dict(p)\n",
    "    id_to_adverb[u['id']] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "[{u'visual_adverbs': [4], u'subject_id': 424258, u'object_id': -1, u'image_id': 516931, u'visual_actions': [109, 156], u'id': 822145749}, {u'visual_adverbs': [17, 9], u'subject_id': 424258, u'object_id': 440510, u'image_id': 516931, u'visual_actions': [116], u'id': 898004752}, {u'visual_adverbs': [15, 10], u'subject_id': 424258, u'object_id': 640623, u'image_id': 516931, u'visual_actions': [29, 91, 75], u'id': 771325559}, {u'visual_adverbs': [17, 11], u'subject_id': 440510, u'object_id': 424258, u'image_id': 516931, u'visual_actions': [88, 115, 117], u'id': 313937370}, {u'visual_adverbs': [16, 13], u'subject_id': 440510, u'object_id': 1995427, u'image_id': 516931, u'visual_actions': [91, 57], u'id': 86762482}, {u'visual_adverbs': [4], u'subject_id': 440510, u'object_id': -1, u'image_id': 516931, u'visual_actions': [114, 147], u'id': 377702020}]\n",
      "==============================\n",
      "[{u'visual_adverbs': [17, 11], u'subject_id': 190190, u'object_id': 28870, u'image_id': 332176, u'visual_actions': [88], u'id': 488067638}, {u'visual_adverbs': [5], u'subject_id': 190190, u'object_id': -1, u'image_id': 332176, u'visual_actions': [111, 151], u'id': 87536935}]\n",
      "==============================\n",
      "[{u'visual_adverbs': [17, 11], u'subject_id': 458675, u'object_id': 304500, u'image_id': 319591, u'visual_actions': [28, 88], u'id': 609014688}, {u'visual_adverbs': [17, 11, 8], u'subject_id': 433991, u'object_id': 304500, u'image_id': 319591, u'visual_actions': [88, 83], u'id': 623232912}]\n",
      "==============================\n",
      "[{u'visual_adverbs': [4], u'subject_id': 445113, u'object_id': -1, u'image_id': 435573, u'visual_actions': [109, 151, 147, 159], u'id': 31397155}, {u'visual_adverbs': [5], u'subject_id': 190190, u'object_id': -1, u'image_id': 332176, u'visual_actions': [111, 151], u'id': 87536935}, {u'visual_adverbs': [5], u'subject_id': 538923, u'object_id': -1, u'image_id': 455654, u'visual_actions': [111, 151, 154], u'id': 22772962}, {u'visual_adverbs': [5], u'subject_id': 458171, u'object_id': -1, u'image_id': 455654, u'visual_actions': [109, 151, 154], u'id': 12795484}, {u'visual_adverbs': [5], u'subject_id': 199724, u'object_id': -1, u'image_id': 25461, u'visual_actions': [102, 151], u'id': 523766735}, {u'visual_adverbs': [5], u'subject_id': 1301897, u'object_id': -1, u'image_id': 353809, u'visual_actions': [111, 151], u'id': 15045059}]\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# each annotation in cocoa is a dictionary with the following properties:\n",
    "\n",
    "#  - id:             unique id within coco-a\n",
    "#  - image_id:       unique id of the image from the MS COCO dataset\n",
    "#  - object_id:      unique id of the object from the MS COCO dataset\n",
    "#  - subject_id:     unique id of the subject from the MS COCO dataset\n",
    "#  - visual_actions: list of visual action ids performed by the subject (with the object if present)\n",
    "#  - visual_adverbs: list of visual adverb ids describing the subject (and object interaction if present)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# find all interactions between any subject and any object in an image\n",
    "image_id = 516931\n",
    "image_interactions = [x for x in cocoa_2 if x['image_id']==image_id]\n",
    "print(image_interactions)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# find all interactions of a subject with any object\n",
    "subject_id = 190190\n",
    "# NOTE: In this image there is no interaction with guitar cause it is not annotated in MS COCO\n",
    "subject_interactions = [x for x in cocoa_2 if x['subject_id']==subject_id]\n",
    "print(subject_interactions)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# find interactions of all subjects with an object\n",
    "object_id = 304500\n",
    "object_interactions = [x for x in cocoa_2 if x['object_id']==object_id]\n",
    "print(object_interactions)\n",
    "print(\"=\"*30)\n",
    "\n",
    "# find all interactions containing a certain visual action\n",
    "va_name = 'play_instrument'\n",
    "va_id   = [x for x in visual_actions if x['name']==va_name][0]['id']\n",
    "interactions = [x for x in cocoa_2 if va_id in x['visual_actions']]\n",
    "print(interactions)\n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/datasets/coco/PythonAPI'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_API_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/datasets/coco/annotations'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_ANN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=50.14s)\n",
      "creating index...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'annotations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-677901a2bb23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mcoco\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mANN_FILE_PATH\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\amirro\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pycocotools\\coco.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, annotation_file)\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;34m'Done (t=%0.2fs)'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreateIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\amirro\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pycocotools\\coco.pyc\u001b[0m in \u001b[0;36mcreateIndex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mcats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mcatToImgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categories'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'annotations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m                 \u001b[0mcatToImgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'annotations'"
     ]
    }
   ],
   "source": [
    "# coco-a is organized to be easily integrable with MS COCO\n",
    "\n",
    "# load coco annotations\n",
    "ANN_FILE_PATH = \"{0}/instances_{1}.json\".format(COCO_ANN_DIR,'train2014')\n",
    "if COCO_API_DIR not in sys.path:\n",
    "    sys.path.append( COCO_API_DIR )\n",
    "from pycocotools.coco import COCO\n",
    "coco = COCO( ANN_FILE_PATH )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize an image with subject and object\n",
    "# and print the interaction annotations\n",
    "\n",
    "# object_id == -1 means that the annotation is describing a subject and not an interaction\n",
    "interaction  = random.choice([x for x in cocoa_2 if x['object_id']!=-1 if len(x['visual_actions'])>2])\n",
    "image_id     = interaction['image_id']\n",
    "\n",
    "subject_id   = interaction['subject_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_anns = coco.loadAnnotations({'im_id_list':[image_id]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_to_id_dict(myList):\n",
    "    res = {}\n",
    "    for p in myList:\n",
    "        q = dict(p)\n",
    "        res[q['id']] = q    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_to_category = coco.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_anns_dict = list_to_id_dict(image_anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "object_id    = interaction['object_id']\n",
    "object_cat   = coco.cats[object_anns['category_id']]['name']\n",
    "\n",
    "\n",
    "\n",
    "object_anns  = coco.loadAnnotations(object_id)[0]\n",
    "subject_anns = coco.loadAnnotations(subject_id)[0]\n",
    "\n",
    "\n",
    "\n",
    "v_actions    = interaction['visual_actions']\n",
    "v_adverbs    = interaction['visual_adverbs']\n",
    "\n",
    "print(\"Image ID:  [{0}]\".format(image_id))\n",
    "print(\"Subject ID:[{0}]\".format(subject_id))\n",
    "print(\"Object ID: [{0}], Category: [{1}]\".format(object_id,object_cat))\n",
    "\n",
    "print(\"\\nVisual Actions:\")\n",
    "for va_id in v_actions:\n",
    "    va = [x for x in visual_actions if x['id']==va_id][0]\n",
    "    print(\"  - id:[{0}], name:[{1}]\".format(va['id'],va['name']))\n",
    "    \n",
    "print(\"\\nVisual Adverbs:\")\n",
    "for va_id in v_adverbs:\n",
    "    va = [x for x in visual_adverbs if x['id']==va_id][0]\n",
    "    print(\"  - id:[{0}], name:[{1}]\".format(va['id'],va['name']))\n",
    "\n",
    "img = coco.loadImgs(image_id)[0]\n",
    "I = io.imread(\"{0}/{1}/{2}\".format(COCO_IMG_DIR,'train2014',img['file_name']))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(I) \t\n",
    "coco.showAnns([subject_anns,object_anns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0b946905ae50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0msubject_id\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0minteraction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msubject_anns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadAnnotations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mobject_id\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0minteraction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'object_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\amirro\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pycocotools\\coco.pyc\u001b[0m in \u001b[0;36mloadAnnotations\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mins_id_lists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# universal filtering params for all types of annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;34m'im_id_list'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             ins_id_lists.append( [ x['id'] for x in\n\u001b[0;32m    119\u001b[0m                                    (itertools.chain(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "\n",
    "# visualize an image with subject and object\n",
    "# and print the interaction annotations\n",
    "\n",
    "# object_id == -1 means that the annotation is describing a subject and not an interaction\n",
    "interaction  = random.choice([x for x in cocoa_2 if x['object_id']!=-1 if len(x['visual_actions'])>2])\n",
    "image_id     = interaction['image_id']\n",
    "\n",
    "subject_id   = interaction['subject_id']\n",
    "subject_anns = coco.loadAnnotations(subject_id)[0]\n",
    "\n",
    "object_id    = interaction['object_id']\n",
    "object_anns  = coco.loadAnnotations(object_id)[0]\n",
    "object_cat   = coco.cats[object_anns['category_id']]['name']\n",
    "\n",
    "v_actions    = interaction['visual_actions']\n",
    "v_adverbs    = interaction['visual_adverbs']\n",
    "\n",
    "print(\"Image ID:  [{0}]\".format(image_id))\n",
    "print(\"Subject ID:[{0}]\".format(subject_id))\n",
    "print(\"Object ID: [{0}], Category: [{1}]\".format(object_id,object_cat))\n",
    "\n",
    "print(\"\\nVisual Actions:\")\n",
    "for va_id in v_actions:\n",
    "    va = [x for x in visual_actions if x['id']==va_id][0]\n",
    "    print(\"  - id:[{0}], name:[{1}]\".format(va['id'],va['name']))\n",
    "    \n",
    "print(\"\\nVisual Adverbs:\")\n",
    "for va_id in v_adverbs:\n",
    "    va = [x for x in visual_adverbs if x['id']==va_id][0]\n",
    "    print(\"  - id:[{0}], name:[{1}]\".format(va['id'],va['name']))\n",
    "\n",
    "img = coco.loadImgs(image_id)[0]\n",
    "I = io.imread(\"{0}/{1}/{2}\".format(COCO_IMG_DIR,'train2014',img['file_name']))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(I) \t\n",
    "coco.showAnns([subject_anns,object_anns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coco.showAnns?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
